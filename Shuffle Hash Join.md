В механизме 'Shuffle Hash Join' сначала два набора входных данных выравниваются в соответствии с выбранной схемой разделения (партиционирования) выходных данных. В случае, если один или оба набора входных данных не соответствуют выбранной схеме разбиения, для достижения соответствия используется операция перемешивания (shuffle) перед фактическим выполнением Join.

После того, как соответствие выбранной схеме разбиения выходных данных обеспечено для обоих входных наборов данных, Shuffle Hash выполняет операцию Join, для каждого выходного раздела, используя стандартный подход Hash Join. То есть, для каждого выходного раздела сначала строится хэш-таблица из соответствующего раздела меньшего входного набора данных, а затем соответствующий раздел большего входного набора данных соединяется с построенной хэш-таблицей.

> Требования к памяти исполнителей относительно меньше в случае "Shuffle Hash Join" по сравнению с "Broadcast Hash Join". Это связано с тем, что хэш-таблица строится только на определенном разделе меньшего набора входных данных. Таким образом, если вы предоставляете большое количество выходных разделов и у вас большое количество исполнителей с подходящей конфигурацией памяти, вы можете достичь более высокой производительности для операции Join с помощью 'Shuffle Hash Join'. Однако эффективность будет ниже, чем у 'Broadcast Hash Join', если Spark потребуется выполнить дополнительную операцию перемешивания на одном или обоих входных наборах данных для соответствия выходному разделению.