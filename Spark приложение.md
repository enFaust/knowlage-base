Spark приложение состоит из драйвера (driver) и набора исполнителей (executors)

Драйвер запускает функцию main() и отвечает за 3 вещи:
1) Пользовательский ввод
2) Хранение информации о Spark приложении
3) Анализ, распределение и планирование работы между executors

Драйвер хранит всю информацию на протяжении всей жизни приложения.
Исполнитель отвечает за выполнение работы, порученую драйвером. 
У них 2 обязанности:
- Выполнение кода, который назначил драйвер
- Отправку состояние обратно драйверу

На рисунке [[The architecture of a Spark Application]] показано как [[Менеджеры кластеров|Менеджер кластера]]  управляет физическими машинами и распределяет ресурсы между Spark приложениями.
На данной картинке изображено 4 исполнителя справа и драйвер слева.

[[Spark режимы]]

Каждый языковой API использует одинаковые концепции. [[Spark Session]] является точкой входа для запуска кода Spark. При написании кода на Scala или R вы не пишете явно JVM инстукции, Spark сам переводит написанный код в исполняемый на JVM исполнителях. На это й картинке есть схема выполнения:
[[The relationship between the SparkSession and Spark’s Language API]]

[[Spark API]]
[[Spark Session]]
[[Partitions]]
[[Transformations]]
[[Lazy Evaluation]]
[[Action]]
[[Spark UI]]
